{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contained-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "sys.path.append(r'C:\\Temp\\SoundOfAI\\rg_text_to_sound\\tts_pipeline\\src')\n",
    "from match_word_to_words import word_to_words_matcher\n",
    "target_word_pairs = [('Bright', 'Dark'), ('Full', 'Hollow'),( 'Smooth', 'Rough'), ('Warm', 'Metallic'), ('Clear', 'Muddy'), ('Thin', 'Thick'), ('Pure', 'Noisy'), ('Rich', 'Sparse'), ('Soft', 'Hard')]\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protecting-browser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bright_vs_dark</th>\n",
       "      <th>full_vs_hollow</th>\n",
       "      <th>smooth_vs_rough</th>\n",
       "      <th>warm_vs_metallic</th>\n",
       "      <th>clear_vs_muddy</th>\n",
       "      <th>thin_vs_thick</th>\n",
       "      <th>pure_vs_noisy</th>\n",
       "      <th>rich_vs_sparse</th>\n",
       "      <th>soft_vs_hard</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>25</td>\n",
       "      <td>60</td>\n",
       "      <td>75</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "      <td>93</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>sitar-like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>29</td>\n",
       "      <td>71</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>76</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>50</td>\n",
       "      <td>Full</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bright_vs_dark  full_vs_hollow  smooth_vs_rough  warm_vs_metallic  \\\n",
       "0              63              25               60                75   \n",
       "1              68              29               71                22   \n",
       "\n",
       "   clear_vs_muddy  thin_vs_thick  pure_vs_noisy  rich_vs_sparse  soft_vs_hard  \\\n",
       "0              11             66             93              19            50   \n",
       "1              31             76             35              29            50   \n",
       "\n",
       "  description  \n",
       "0  sitar-like  \n",
       "1        Full  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1303, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('text_to_qualities.csv')\n",
    "colnames = df.columns\n",
    "display(df.head(2))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "super-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "rowlist =[]\n",
    "for r,w in generate_training_examples(df):\n",
    "    wordlist.append(w)\n",
    "    rowlist.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "healthy-bulgaria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2667, 670)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_word_list = np.unique(wordlist).tolist()\n",
    "len(wordlist),len(unique_word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-chance",
   "metadata": {},
   "source": [
    "# word2word matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "appropriate-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_examples(df):\n",
    "    for irow,row in df.iterrows():\n",
    "        if ', ' in row.description:\n",
    "            splitlist = row.description.split(', ')\n",
    "        else:\n",
    "            splitlist=[row.description]\n",
    "        for word in splitlist:\n",
    "            yield row,word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "robust-visitor",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_list = [tup[0] for tup in target_word_pairs]+[tup[1] for tup in target_word_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "general-print",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "abroad-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2wm = word_to_words_matcher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "boolean-ownership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n"
     ]
    }
   ],
   "source": [
    "import ipdb\n",
    "print('x')\n",
    "w2wm.build(target_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fourth-advocate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 300)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2wm.clusterer.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "incredible-strengthening",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2wm.match_word_to_words('greek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-settlement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "confidential-animation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Full', 'Rough']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2wm.predict(['greek','sluggish'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "suburban-property",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32mc:\\temp\\soundofai\\rg_text_to_sound\\playground\\beat_toedtli\\word2word_matching\\match_word_to_words.py\u001b[0m(70)\u001b[0;36mpredict\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m     68 \u001b[1;33m        \u001b[0mvector_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     69 \u001b[1;33m        \u001b[0mclusterind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclusterer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 70 \u001b[1;33m        \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclusterind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     71 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     72 \u001b[1;33m    \u001b[1;32mdef\u001b[0m \u001b[0mdispose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  clusterind\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([ 1, 11])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.target_tokens_array[clusterind].tolist()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Full', 'Rough']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "received-privilege",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 15, ..., 17, 16, 17])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2wm.predict_index(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-plumbing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "polyphonic-philip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_occurrence_prediction(wordlist,w2wm,variant=1):\n",
    "    \"\"\"\n",
    "    predict that word that occurs most often in a wordlist\n",
    "    \"\"\"\n",
    "    #set_trace()\n",
    "    if variant==2:\n",
    "        yhat = []\n",
    "        for word in wordlist:\n",
    "            yhat_elems = w2wm.predict([word])\n",
    "            yhat_elem = max(set(yhat_elems), key = l.count)\n",
    "            yhat.append(yhat_elem)\n",
    "    elif variant==1:\n",
    "        yhat = [max(set(w2wm.predict([word])), key = l.count) for word in wordlist]\n",
    "\n",
    "    return yhat\n",
    "yhat1 = np.array(max_occurrence_prediction(wordlist,w2wm,variant=1))\n",
    "yhat2 = np.array(max_occurrence_prediction(wordlist,w2wm,variant=2))\n",
    "yhat1==yhat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "shared-puzzle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Full', 'Noisy', 'Sparse', 'Rough', 'Clear', 'Thin', 'Hollow',\n",
       "       'Soft', 'Hard', 'Dark', 'Bright', 'Warm', 'Pure', 'Muddy',\n",
       "       'Metallic', 'Smooth', 'Thick', 'Rich'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(yhat1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "hydraulic-stuart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         sitar-like\n",
       "1               Full\n",
       "2            wailing\n",
       "3              greek\n",
       "4            zooming\n",
       "            ...     \n",
       "2662         country\n",
       "2663       distorted\n",
       "2664        bouncing\n",
       "2665           zoomy\n",
       "2666    blues guitar\n",
       "Length: 2667, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df_pairs:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "adjacent-sleeve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bright', 'Dark') bright_vs_dark\n",
      "('Full', 'Hollow') full_vs_hollow\n",
      "('Smooth', 'Rough') smooth_vs_rough\n",
      "('Warm', 'Metallic') warm_vs_metallic\n",
      "('Clear', 'Muddy') clear_vs_muddy\n",
      "('Thin', 'Thick') thin_vs_thick\n",
      "('Pure', 'Noisy') pure_vs_noisy\n",
      "('Rich', 'Sparse') rich_vs_sparse\n",
      "('Soft', 'Hard') soft_vs_hard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('distorted', 'soft_vs_hard', 50, ('Soft', 'Hard'))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for irow,(col,word,word_pair) in enumerate(zip(df_pairs.columns,ser_words,target_word_pairs)):\n",
    "    curr_col = df_pairs.iloc[irow,:][col]\n",
    "    #w2wm = word_to_words_matcher()\n",
    "    \n",
    "    print(word_pair,col)\n",
    "word,col,curr_col,word_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "representative-vault",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e6d2fafab48a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mser_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf_pairs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrRow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrRow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcurrRow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrowlist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwordpair_matcher_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mword_pair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_pairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_word_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wordlist' is not defined"
     ]
    }
   ],
   "source": [
    "ser_words = wordlist = pd.Series(wordlist)\n",
    "df_pairs = pd.DataFrame([currRow[currRow.index[:-1]] for currRow in rowlist])\n",
    "\n",
    "wordpair_matcher_dict=dict()\n",
    "for col,word_pair in zip(df_pairs.columns,target_word_pairs):\n",
    "    w2wm = word_to_words_matcher()\n",
    "    w2wm.build(list(word_pair))\n",
    "    wordpair_matcher_dict[col]=w2wm\n",
    "col,word_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accomplished-workplace",
   "metadata": {},
   "source": [
    "# word pair estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "impressive-zealand",
   "metadata": {},
   "outputs": [],
   "source": [
    "from match_word_to_words import word_to_wordpair_estimator\n",
    "df_pairs = pd.DataFrame([currRow[currRow.index[:-1]] for currRow in rowlist])\n",
    "\n",
    "w2wpe = word_to_wordpair_estimator()\n",
    "w2wpe.build(df_pairs.columns.tolist(),target_word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "infrared-morrison",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy      0.000 0 0 closer to  dummy than dummy\n",
      "bright     0.000 0 1 closer to  Bright than Dark\n",
      "shiny      0.470 0 1 closer to  Bright than Dark\n",
      "gloomy     0.523 1 0 closer to  Dark than Bright\n",
      "day        0.497 0 1 closer to  Bright than Dark\n",
      "night      0.505 1 0 closer to  Dark than Bright\n",
      "dark       1.000 1 0 closer to  Dark than Bright\n",
      "useless    0.499 0 1 closer to  Bright than Dark\n"
     ]
    }
   ],
   "source": [
    "dummy = 'dummy'\n",
    "print(f'{dummy:<10}',f'{0.000:1.3f}', 0,0,'closer to ',dummy,'than',dummy)\n",
    "(w2wpe.match_word_to_wordpair('bright','bright_vs_dark'),\n",
    " w2wpe.match_word_to_wordpair('shiny','bright_vs_dark'),\n",
    " w2wpe.match_word_to_wordpair('gloomy','bright_vs_dark'),\n",
    " w2wpe.match_word_to_wordpair('day','bright_vs_dark'),\n",
    " w2wpe.match_word_to_wordpair('night','bright_vs_dark'),\n",
    " w2wpe.match_word_to_wordpair('dark','bright_vs_dark'),\n",
    " w2wpe.match_word_to_wordpair('useless','bright_vs_dark')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "pressed-brunei",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[1,2]\n",
    "a.append(3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "global-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_threshold_plot(wordpairname,w2wpe,thlist=None):\n",
    "    if thlist is None:\n",
    "        thlist = [0,0.2,*np.linspace(0.4,0.5,20).tolist()]\n",
    "    countlist = []\n",
    "    for threshold in thlist:\n",
    "        count = 0\n",
    "        for word in unique_word_list:\n",
    "            d = w2wpe.match_word_to_wordpair(word,wordpairname)\n",
    "            proximity,sliderval,closest,fartherst = d['proximity'],d['slider value'],d['closest word'],d['other word']\n",
    "            if proximity < threshold:\n",
    "                #print(f'{word:<20}',f'{proximity:1.3f}',f'{sliderval:1.3f}',closest,fartherst)\n",
    "                count +=1\n",
    "        countlist.append(count)\n",
    "    return countlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "sophisticated-monday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'proximity': 0.0,\n",
       " 'slider value': 0.0,\n",
       " 'closest dist': 0.0,\n",
       " 'other dist': 6.263573686346848,\n",
       " 'closest word': 'Soft',\n",
       " 'other word': 'Hard'}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "complete-valley",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bright_vs_dark       5.497\n",
      "full_vs_hollow       7.630\n",
      "smooth_vs_rough      6.122\n",
      "warm_vs_metallic     8.490\n",
      "clear_vs_muddy       7.037\n",
      "thin_vs_thick        4.594\n",
      "pure_vs_noisy        8.466\n",
      "rich_vs_sparse       7.708\n",
      "soft_vs_hard         6.264\n"
     ]
    }
   ],
   "source": [
    "for wpname in w2wpe.wordpair_names_dict:\n",
    "    twp = w2wpe.wordpair_names_dict[wpname]\n",
    "    d = w2wpe.match_word_to_wordpair(twp[0],wpname)\n",
    "    d2 = w2wpe.match_word_to_wordpair(twp[1],wpname)\n",
    "    #print(d['slider value'],d2['slider value'],d['other dist'])\n",
    "    print(f'{wpname:<20}',f\"{d['other dist']:1.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model= 'en_core_web_sm'\n",
    "w2wpe = word_to_wordpair_estimator()\n",
    "w2wpe.build(df_pairs.columns.tolist(),target_word_pairs,lang_model= lang_model)\n",
    "plt.figure(1,figsize=(15,15))\n",
    "wordpairname='bright_vs_dark'\n",
    "counts=[]\n",
    "for iplt,wordpairname in enumerate(df_pairs.columns.tolist()):\n",
    "    plt.subplot(3,3,iplt+1)\n",
    "    countlist = create_threshold_plot(wordpairname,w2wpe)\n",
    "    counts.append(countlist)\n",
    "    plt.plot(thlist,countlist,marker='.')\n",
    "    plt.xlabel('threshol');\n",
    "    plt.ylabel('Number of Words with\\nproximity < threshold')\n",
    "    plt.title(wordpairname)\n",
    "plt.suptitle(f'{lang_model},Nr unique words: {len(unique_word_list)}')\n",
    "plt.savefig(f'thresholdplots_{lang_model}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "postal-glass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  8,\n",
       "  10,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  15,\n",
       "  18,\n",
       "  24,\n",
       "  29,\n",
       "  41,\n",
       "  72,\n",
       "  129,\n",
       "  232,\n",
       "  438,\n",
       "  670],\n",
       " [0,\n",
       "  4,\n",
       "  5,\n",
       "  8,\n",
       "  11,\n",
       "  17,\n",
       "  28,\n",
       "  34,\n",
       "  49,\n",
       "  104,\n",
       "  139,\n",
       "  161,\n",
       "  190,\n",
       "  222,\n",
       "  267,\n",
       "  307,\n",
       "  366,\n",
       "  428,\n",
       "  483,\n",
       "  544,\n",
       "  605,\n",
       "  670],\n",
       " [0,\n",
       "  4,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  6,\n",
       "  8,\n",
       "  8,\n",
       "  11,\n",
       "  15,\n",
       "  22,\n",
       "  29,\n",
       "  39,\n",
       "  52,\n",
       "  85,\n",
       "  179,\n",
       "  242,\n",
       "  313,\n",
       "  381,\n",
       "  470,\n",
       "  566,\n",
       "  670],\n",
       " [0,\n",
       "  5,\n",
       "  9,\n",
       "  10,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  21,\n",
       "  25,\n",
       "  28,\n",
       "  32,\n",
       "  38,\n",
       "  45,\n",
       "  65,\n",
       "  94,\n",
       "  130,\n",
       "  197,\n",
       "  276,\n",
       "  343,\n",
       "  452,\n",
       "  588,\n",
       "  670],\n",
       " [0,\n",
       "  5,\n",
       "  9,\n",
       "  14,\n",
       "  18,\n",
       "  25,\n",
       "  38,\n",
       "  58,\n",
       "  81,\n",
       "  97,\n",
       "  126,\n",
       "  196,\n",
       "  227,\n",
       "  274,\n",
       "  311,\n",
       "  355,\n",
       "  408,\n",
       "  451,\n",
       "  521,\n",
       "  566,\n",
       "  621,\n",
       "  670],\n",
       " [0, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 7, 9, 10, 10, 18, 30, 83, 196, 447, 670],\n",
       " [0,\n",
       "  4,\n",
       "  11,\n",
       "  11,\n",
       "  13,\n",
       "  13,\n",
       "  16,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  32,\n",
       "  33,\n",
       "  38,\n",
       "  48,\n",
       "  63,\n",
       "  96,\n",
       "  141,\n",
       "  213,\n",
       "  291,\n",
       "  401,\n",
       "  553,\n",
       "  670],\n",
       " [0,\n",
       "  4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  7,\n",
       "  8,\n",
       "  8,\n",
       "  13,\n",
       "  21,\n",
       "  33,\n",
       "  51,\n",
       "  82,\n",
       "  134,\n",
       "  211,\n",
       "  304,\n",
       "  447,\n",
       "  555,\n",
       "  670],\n",
       " [0,\n",
       "  3,\n",
       "  7,\n",
       "  7,\n",
       "  8,\n",
       "  10,\n",
       "  11,\n",
       "  16,\n",
       "  21,\n",
       "  22,\n",
       "  32,\n",
       "  43,\n",
       "  64,\n",
       "  90,\n",
       "  127,\n",
       "  167,\n",
       "  257,\n",
       "  310,\n",
       "  385,\n",
       "  474,\n",
       "  573,\n",
       "  670]]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "regulation-eugene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-127-c926b92ab5e0>\u001b[0m(3)\u001b[0;36mf\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      2 \u001b[1;33m    \u001b[0mipdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 3 \u001b[1;33m    \u001b[1;32mreturn\u001b[0m \u001b[0mwordpair_matcher_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bright_vs_dark'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch_word_to_words\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sunny'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      4 \u001b[1;33m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bright'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f():\n",
    "    ipdb.set_trace()\n",
    "    return wordpair_matcher_dict['bright_vs_dark'].match_word_to_words('sunny')\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fantastic-filling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2667,), (2667,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([np.where(row['bright_vs_dark']>=50,1,0) for row in rowlist])\n",
    "y.shape,yhat1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "taken-paraguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2667,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_binary = np.array([0 if yhatelem==target_word_pair[0] else 1 for yhatelem in yhat1])\n",
    "yhat_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yhat),len(rowlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-chile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y,yhat_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-drilling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_detailed = pd.DataFrame(index=wordlist)\n",
    "df_detailed.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [w for r,w in generate_training_examples(df)]\n",
    "rowlist =  [r for r,w in generate_training_examples(df)]\n",
    "\n",
    "acc_scores=dict()\n",
    "for target_word_pair,opposite_quality_pair in zip(target_word_pairs,colnames):\n",
    "    y = np.array([np.where(row[opposite_quality_pair]>=50,1,0) for row in rowlist])\n",
    "    \n",
    "    print(target_word_pair,opposite_quality_pair)\n",
    "    w2wm = word_to_words_matcher()\n",
    "    w2wm.build(target_word_pair)\n",
    "    yhat1 = np.array(f(wordlist,w2wm,variant=1))\n",
    "    df_detailed[opposite_quality_pair] = yhat1\n",
    "    yhat_binary = np.array([0 if yhatelem==target_word_pair[0] else 1 for yhatelem in yhat1])\n",
    "    acc_score = accuracy_score(y,yhat_binary)\n",
    "    print(f'{acc_score:1.3f}')\n",
    "    acc_scores[opposite_quality_pair] = acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_detailed.shape)\n",
    "df_detailed.to_excel('predicted_qualities.xlsx')\n",
    "df_detailed.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(acc_scores).plot.bar(ylabel='accuracy')\n",
    "plt.plot(plt.xlim(),[0.5,0.5],'--',c='k')\n",
    "plt.title(f'Accuracy of Spacy word vectors in predicting\\ntext_to_qualities.csv ({len(wordlist)} qualities)')\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-advancement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
